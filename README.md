# Challenge Telecom X ‚Äì Parte 2: Predicci√≥n de Cancelaci√≥n (Churn)

## üéØDescripci√≥n del Proyecto

Desarrollar un modelo predictivo para identificar clientes con alto riesgo de cancelaci√≥n de servicios, permitiendo a la empresa tomar acciones preventivas y estrat√©gicas para reducir la tasa de abandono y optimizar la retenci√≥n de clientes.


## üìä Objetivos del Desaf√≠o
* Preparar los datos para el modelado (tratamiento, codificaci√≥n, normalizaci√≥n).

* Realizar an√°lisis de correlaci√≥n y selecci√≥n de variables.

* Entrenar dos o m√°s modelos de clasificaci√≥n.

* Evaluar el rendimiento de los modelos con m√©tricas.

* Interpretar los resultados, incluyendo la importancia de las variables.

* Crear una conclusi√≥n estrat√©gica se√±alando los principales factores que influyen en la cancelaci√≥n.

### Componentes principales
* An√°lisis exploratorio de datos
* Preprocesamiento e ingenieria de caracteristicas
* Modelado predictivo de clasificaci√≥n
* Evaluaci√≥n de factores de riesgo de cancelaci√≥n

## Estructura del proyecto

- **TelecomX_LATAM.ipynb**: Notebook principal con todo el proceso de an√°lisis, desde la carga y limpieza de datos hasta la visualizaci√≥n y conclusiones.
- **datos_tratados**: Fuente de datos tratados en proyecto anterior. 
- **modelo_xgboost_reducido.plk**: Modelo XGBOOST generado
- **Informe TelecomX - Parte 2.pdf**: Informe detallado sobre resultados y hallazgos

### Datos iniciales 
```
Data columns (total 24 columns):
 #   Column                             Non-Null Count  Dtype  
---  ------                             --------------  -----  
 0   ID Cliente                         7043 non-null   object 
 1   Abandono                           7043 non-null   int64  
 2   G√©nero                             7043 non-null   object 
 3   Mayor de 65 a√±os                   7043 non-null   bool   
 4   Tiene Pareja                       7043 non-null   int64  
 5   Tiene Dependientes                 7043 non-null   int64  
 6   Duraci√≥n del Contrato (meses)      7043 non-null   int64  
 7   Servicio Telef√≥nico                7043 non-null   int64  
 8   M√∫ltiples L√≠neas                   7043 non-null   int64  
 9   Servicio de Internet               7043 non-null   object 
 10  Seguridad en L√≠nea                 7043 non-null   int64  
 11  Respaldo en L√≠nea                  7043 non-null   int64  
 12  Protecci√≥n del Dispositivo         7043 non-null   int64  
 13  Soporte T√©cnico                    7043 non-null   int64  
 14  TV por Cable                       7043 non-null   int64  
 15  Streaming de Pel√≠culas             7043 non-null   int64  
 16  Tipo de Contrato                   7043 non-null   object 
 17  Facturaci√≥n Sin Papel              7043 non-null   int64  
 18  M√©todo de Pago                     7043 non-null   object 
 19  Costo Mensual                      7043 non-null   float64
 20  Costo Total                        7043 non-null   float64
 21  Costo Diario                       7043 non-null   float64
 22  Rango de Contrato                  7043 non-null   object 
 23  Cantidad de Servicios Contratados  7043 non-null   int64  
```

## √çndice de Contenidos de TelecomX_LATAM.ipynb

### 1. Preparaci√≥n de Datos
- 1.1 Carga y Exploraci√≥n Inicial: Se presenta la composici√≥n de los datos, identificando la clase principal.
- 1.2 Limpieza y Preparaci√≥n de Datos: Se identifican y analizan variables relevantes, describiendo sus asimetr√≠as y caracter√≠sticas de distribuci√≥n. Tambi√©n se incluye el an√°lisis de variables binarias y servicios adicionales, destacando su relaci√≥n con la probabilidad de abandono y la importancia de algunos servicios.
- 1.3 An√°lisis de Gr√°ficos para Variables Num√©ricas: Se identifican y analizan variables relevantes, describiendo sus asimetr√≠as y caracter√≠sticas de distribuci√≥n. Tambi√©n se incluye el an√°lisis de variables binarias y servicios adicionales, destacando su relaci√≥n con la probabilidad de abandono y la importancia de algunos servicios.
-  1.4 Gr√°ficos de Variables Categ√≥ricas:Se identifican y analizan variables categ√≥ricas, destacando su relaci√≥n con cancelaci√≥n del servicio.
- 1.5 Informaci√≥n Mutua: Se aplica la t√©cnica para medir la dependencia entre dos variables e identificar caracter√≠sticas por su relevancia, esto nos permitir√° simplificar el modelo se ser necesario.
- 1.6 Detecci√≥n y Tratamiento de Outliers: Se aplican transformaciones (logar√≠tmica, Box-Cox y ra√≠z cuadrada) que nos ayudan a identificar y transformar valores at√≠picos que pueden distorsionar el an√°lisis estad√≠stico y el rendimiento de modelos.
- 1.7 Codificaci√≥n de Variables Categ√≥ricas: Se identifican las correlaciones positivas y negativas de diversas variables con la probabilidad de abandono.

### 2. Preprocesamiento
- 2.1 Separaci√≥n de Datos: Dividir el conjunto de datos en subconjuntos para entrenamiento, validaci√≥n y prueba en una proporci√≥n 80% entrenamiento, 20% prueba. 
- 2.2 Balanceo de Clases: Aunque se evidencia un desbalanceo, no se aplica ninguna t√°cnica de balanceo debido a que la relaci√≥n de desbalanceo (2.77) se considera moderada (no cr√≠tica) y se puede tratar en el modelado.

### 3. Entrenamiento de Modelos
- 3.1 Selecci√≥n de Algoritmos: Selecci√≥n de acuerdo al tipo de problema a resolver y caracteristicas de los datos, en este caso es un problema de clasificaci√≥n. Se propone: Random Forest, CatBoost y XGBoost.
- 3.2 Random Forest: Robusto contra overfitting, maneja bien features no lineales, bueno con datasets desbalanceados, menos sensible a outliers.
- 3.3 CatBoost. Bueno con variables categ√≥ricas, reduce sesgo por codificaci√≥n, mejor rendimiento con pocos datos.
- 3.4 XGBoost. Mayor precisi√≥n predictiva, regularizaci√≥n integrada, m√°s r√°pido computacionalmente y maneja muy bien la probabilidad de abandono

### 4. Evaluaci√≥n de Modelos
(Accuracy, Precision, Recall, F1-score, Matriz de confusi√≥n)
- 4.1 M√©tricas Random Forest.
- 4.2 M√©tricas CatBoost
- 4.3 M√©tricas XGBoost

### 5. Ajuste de Modelos
(Se realizan ajustes al algoritmo para mejorar el rendimiento observado en la evaluaci√≥n)
- 5.1 Random Forest. 
- 5.2 CatBoost.
- 5.3 XGBoost.
- 5.4 Evaluaci√≥n de Modelos Ajustados. Se observa una mejora en el rendimiento respecto al primer modelo entrenado en los tres algoritmnos.
- 5.5 An√°lisis de Overfitting. Se evalua la capacidad de generalizaci√≥n de los modelos.
- 5.6 Validaci√≥n Cruzada. Se hace para mejorar la estimaci√≥n de rendimiento y validar la capacidad de generalizaci√≥n.
- 5.7 Dataframe de Variables Reducidas. Se propone reducir la cantidad de variables reducir la complejidad del dataset y luego volver a evaluar los algortimos. Se objerva un amejora significativo en todos, especialmente en XGBoost. 
- 5.8 Ajuste de Umbral. Despues de  observar el ROC se realiza un ajuste de 0.4 para reducir los falsos negativos. 

### 6. Interpretaci√≥n
- 6.1 An√°lisis de Variables Relevantes XGBoost Se revisan las variables mas relevantes para la predicci√≥n de cancelaci√≥n en el modelo XGBoost reducido (el cual ha sido el modelo con mejores resultados).
- 6.2 An√°lisis Complementario Random Forest. se hace un an√°lisis complementario para identificar los factores cr√≠ticos que influyen en la deserci√≥n de clientes y desarrollar estrategias de retenci√≥n m√°s efectivas y personalizadas. 

### 7. Anexos
- Se genera el modelo seleccionado y entrenado: modelo_xgboost_reducido.pkl
- Se realiza una conclusi√≥n del procedimiento y los resultados obtenidos.

## Requisitos

- Python 3.x
- Pandas
- Matplotlib
- Seaborn
- Scikit-learn (sklearn)
- Catboost
- XGBoost
- Jupyter Notebook

## Uso

1. Clona este repositorio.
2. Abre el archivo `TelecomX_LATAM.ipynb` en Jupyter Notebook o Google Colab.
3. Ejecuta las celdas para reproducir el modelado

---
## Uso de modelo entrenado
Para utilizar modelo_xgboost_reducido.pkl en el contexto de predicci√≥n de cancelaci√≥n (churn) de Telecom siga los siguientes pasos:
1. Cargar el modelo entrenado modelo_xgboost_reducido.pkl en el entorno de Python usando la librer√≠a pickle.

```
import pickle

# Guardar modelo
with open('modelo_xgboost_reducido.pkl', 'wb') as archivo:
    pickle.dump(modelo, archivo)

# Cargar modelo
with open('modelo_xgboost_reducido.pkl', 'rb') as archivo:
    modelo_cargado = pickle.load(archivo)
```
2. Cargar los nuevos datos para predicci√≥n.
3. Preparar los nuevos datos de la misma manera que los datos de entrenamiento.
    - Limpieza de datos: Eliminar 'ID Cliente', 'Costo Diario' y 'Duraci√≥n del Contrato (meses)'.
    - Tratamiento de variables num√©ricas.
    - Codificaci√≥n de variables categ√≥ricas y binarias.
    - Selecci√≥n y reducci√≥n de variables: Dado que el modelo XGBoost se optimiz√≥ con un "Dataframe de variables reducidas", es imprescindible que los nuevos datos contengan solo las variables relevantes que fueron seleccionadas para el modelo final.
4. Realizar predicciones:
    - Una vez que los nuevos datos est√©n completamente preparados y tengan la misma estructura y caracter√≠sticas que los datos de entrenamiento, podr√°s pasarlos al modelo cargado para obtener las predicciones de churn.
    - Considera aplicar en el an√°lisis de la curva ROC el umbral a las probabilidades de predicci√≥n.
```
# Predecir
predicciones = modelo_cargado.predict(X_test_nuevos)
probabilidades = modelo_cargado.predict_proba(X_test_nuevos)
```
   
5. Interpretar los resultados. para entender qu√© factores est√°n influyendo en las predicciones de churn para los nuevos clientes.

**Autor:** Ana Sayago  
